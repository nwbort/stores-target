name: Scrape

on:
  push:
  workflow_dispatch:
  schedule:
  - cron: '18 9 * * *'

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    if: ${{ !github.event.repository.is_template }}
    steps:
    - uses: actions/checkout@v4
    - name: Create scrape.sh if it doesn't exist
      run: |
        if [ ! -f "scrape.sh" ]; then
          echo '#!/bin/bash' > scrape.sh
          if [[ "$REPO_DESC" == http://* ]] || [[ "$REPO_DESC" == https://* ]]; then
            echo "./download.sh '$REPO_DESC'" >> scrape.sh
          else
            echo "# ./download.sh 'https://www.example.com/'" >> scrape.sh
          fi
          chmod +x scrape.sh
          echo "Created scrape.sh"
          # And replace README.md
          echo -e "# Scheduled scraper\n\nFor $REPO_DESC" > README.md 
        fi
        chmod +x scrape.sh
        chmod +x download.sh
      env:
        REPO_DESC: ${{ github.event.repository.description }}
    - name: Run the scraper
      run: |
        ./scrape.sh
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.13"
    - name: Extract store details
      run: python extract_stores.py > stores.json
    - name: Commit and push
      run: |-
        git config user.name "Automated"
        git config user.email "actions@users.noreply.github.com"
        git add -A
        timestamp=$(date -u)
        git commit -m "${timestamp}" || exit 0
        git pull --rebase
        git push
